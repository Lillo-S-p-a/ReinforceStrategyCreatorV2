# Benchmark Calculation Code Analysis

## Overview

This document analyzes the benchmark calculation implementation in the backtesting system to identify any potential issues that might explain the significant performance gap between the reinforcement learning model (+40.79%) and benchmark strategies (all negative: -18.26%, -6.98%, -17.37%).

## Code Structure

The benchmark implementation is spread across several files:

1. **benchmarks.py**: Defines the benchmark strategies
   - `BenchmarkStrategy` (base class)
   - `BuyAndHoldStrategy`
   - `SMAStrategy`
   - `RandomStrategy`

2. **evaluation.py**: Contains the `BenchmarkEvaluator` class that orchestrates benchmark comparisons

3. **workflow.py**: Implements the full backtesting workflow, including the `_compare_with_benchmarks` method

## Key Components Analysis

### 1. BenchmarkEvaluator (evaluation.py)

```python
def compare_with_benchmarks(self, test_data: pd.DataFrame, model_metrics: Dict[str, float]) -> Dict[str, Dict[str, float]]:
    # Run benchmark strategies
    benchmarks = {}
    for name, strategy in self.strategies.items():
        benchmarks[name] = strategy.run(test_data)
    
    # Calculate relative performance
    model_pnl = model_metrics["pnl"]
    relative_performance = {}
    
    for name, bench_metrics in benchmarks.items():
        bench_pnl = bench_metrics["pnl"]
        relative_performance[name] = {
            "absolute_difference": model_pnl - bench_pnl,
            "percentage_difference": ((model_pnl / bench_pnl) - 1) * 100 if bench_pnl != 0 else float('inf'),
            "sharpe_ratio_difference": model_metrics["sharpe_ratio"] - bench_metrics["sharpe_ratio"]
        }
```

**Observations:**
- The method calls the `run` method on each strategy with the test data
- Results are compared with model metrics using absolute and percentage differences
- The `percentage_difference` calculation has a potential issue with negative benchmark PnLs

### 2. Benchmark Strategy Implementation (benchmarks.py)

Each strategy follows a similar pattern:

1. Read price data from the DataFrame
2. Implement strategy-specific logic
3. Track portfolio values
4. Calculate performance metrics

#### Price Data Reading

```python
# Try different possible column names
if 'close' in data.columns:
    prices = data['close'].values
elif 'Close' in data.columns:
    prices = data['Close'].values
elif 'Adj Close' in data.columns:
    prices = data['Adj Close'].values
else:
    logger.error(f"Cannot find price data in columns: {data.columns}")
    return {
        # Default metrics...
    }

# Ensure price data is a 1D numpy array of float type
prices = np.array(prices, dtype=float).flatten()
```

**Observations:**
- Multiple column name variations are tried (case-sensitive)
- Error handling returns default values if column not found
- Type conversion ensures consistent array handling

### 3. Portfolio Value Calculation

#### Buy and Hold Strategy Example:

```python
# Calculate number of shares to buy
initial_price = float(prices[0])
shares = self.initial_balance / initial_price
shares = shares * (1 - self.transaction_fee)  # Account for transaction fee

# Calculate portfolio value over time
portfolio_values = [float(self.initial_balance)]  # Initial balance
for price in prices[1:]:
    portfolio_value = float(shares * price)
    portfolio_values.append(portfolio_value)

# Convert portfolio values to numpy array to ensure consistency
portfolio_values = np.array(portfolio_values, dtype=float).tolist()
```

**Observations:**
- Initial balance is used to buy shares at first price
- Transaction fee is properly deducted when buying
- Portfolio value is tracked over time
- Type consistency is maintained with explicit conversions

### 4. Metrics Calculation

```python
def calculate_metrics(self, portfolio_values, trades, profitable_trades):
    # Convert portfolio values to numpy array of float type to ensure consistency
    portfolio_values = np.array(portfolio_values, dtype=float)
    
    # Calculate returns
    returns = np.diff(portfolio_values) / portfolio_values[:-1]
    
    # Calculate metrics
    initial_value = portfolio_values[0]
    final_value = portfolio_values[-1]
    pnl = final_value - initial_value
    pnl_percentage = (pnl / initial_value) * 100
    
    # Calculate Sharpe ratio (annualized)
    if len(returns) > 1 and np.std(returns) > 0:
        sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252)  # Annualized
    else:
        sharpe_ratio = 0
        
    # Calculate max drawdown
    peak = portfolio_values[0]
    max_drawdown = 0
    
    for value in portfolio_values:
        if value > peak:
            peak = value
        drawdown = (peak - value) / peak
        max_drawdown = max(max_drawdown, drawdown)
    
    # Calculate win rate
    if trades > 0:
        win_rate = profitable_trades / trades
    else:
        win_rate = 0
```

**Observations:**
- Portfolio values are properly converted to numpy array
- Returns are calculated as percentage changes
- PnL is calculated as final minus initial value
- Sharpe ratio uses annualized formula with proper error handling
- Max drawdown calculation is standard and correct
- Win rate calculation depends on trade and profitable_trades parameters

## Potential Issues/Discrepancies

Based on this code analysis, several factors might explain the significant performance gap:

### 1. Data Handling

- **Different Price Columns**: The benchmark strategies try multiple column names ('close', 'Close', 'Adj Close'). If the RL model uses a different column, this could cause discrepancies.
  
- **Type Consistency**: The benchmark code has multiple explicit type conversions. If the core model doesn't handle types consistently, results could differ.

### 2. Trading Mechanics

- **Transaction Fees**: Benchmark strategies apply transaction fees consistently. If the RL model handles fees differently, this could adjust performance.
  
- **The "trades: 0" Anomaly**: The test metrics show 0 trades despite having a PnL and win rate. This suggests the metrics calculation or trading definition differs between the model and benchmarks.

### 3. Performance Calculation

- **Portfolio Tracking**: Benchmark strategies track portfolio value at each time step. If the RL model uses a different tracking mechanism, this could lead to different performance metrics.
  
- **Sharpe Ratio Calculation**: The annualization factor (âˆš252) assumes daily data. If the data has a different frequency, this could skew the Sharpe ratio calculations.

### 4. Benchmark Strategies Implementation

- **Buy and Hold**: Simply buys at the beginning and holds. Implementation looks correct.
  
- **SMA Strategy**: Uses moving average crossovers for signals. The alignment of short and long MAs might have issues that impact performance.
  
- **Random Strategy**: Generates random trade signals. The implementation looks correct, but randomness depends on proper seeding.

## Next Steps

1. **Verify Data Consistency**:
   - Confirm the same price data/columns are used by model and benchmarks
   - Check if the data frequency affects annualization factors

2. **Investigate the "trades: 0" Anomaly**:
   - Determine how trades are counted in the model vs. benchmarks
   - Check for logical errors in trade tracking

3. **Compare Trading Mechanics**:
   - Review how the RL model applies transaction costs
   - Verify position sizing and liquidation logic

4. **Run Independent Benchmark Verification**:
   - Consider implementing a simplified benchmark calculation outside the main system
   - Compare results to identify any systemic issues