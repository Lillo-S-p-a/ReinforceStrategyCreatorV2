+++
id = "TASK-DEVPT-20250508-195300"
title = "Refactor train.py & evaluate_strategy.py for Structured Optimization Workflow"
status = "ðŸŸ¢ Done" # Options: ðŸŸ¡ To Do, ðŸŸ  In Progress, ðŸŸ¢ Done, ðŸ”´ Blocked, âšª Hold
type = "ðŸŒŸ Feature" # Could also be Refactor
priority = "Highest"
created_date = "2025-05-08"
updated_date = "2025-05-08" # Will be updated by PM or Coordinator upon actual merge/completion
due_date = "" # Optional
assigned_to = "dev-python"
coordinator = "TASK-CMD-20250508-194500" # Assumed Commander Task ID for this workflow
tags = ["refactor", "workflow", "rl", "training", "evaluation", "metrics", "config", "python"]
related_docs = [
    "configs/config_EXP001.json",
    "train.py",
    "evaluate_strategy.py",
    "reinforcestrategycreator/trading_environment.py",
    "reinforcestrategycreator/metrics_calculator.py"
]
# --- Git Context (Optional) ---
# branch = "feature/rl-optimization-workflow" # Suggest creating a new branch for this
# commit_hash = ""
+++

# Description

Refactor the `train.py` and `evaluate_strategy.py` scripts to support a structured, iterative optimization workflow as requested by the user and defined by the configuration file format (see `configs/config_EXP001.json`). This involves separating train/test data, externalizing parameters, calculating additional metrics, and standardizing output naming.

# Acceptance Criteria

1.  **Configuration Loading:**
    *   Both `train.py` and `evaluate_strategy.py` accept a `--config` command-line argument specifying the path to a JSON configuration file (like `configs/config_EXP001.json`).
    *   All relevant parameters (RL, Environment, Data dates, Evaluation settings) are loaded from this config file, overriding any previous hardcoded values.
    *   The scripts log which config file is being used.
2.  **`train.py` Modifications:**
    *   Uses `train_start_date` and `train_end_date` from the config's `data_params` section to fetch data via `fetch_historical_data`.
    *   Saves the trained Keras model using the `experiment_id` from the config in the filename (e.g., `models/model_{experiment_id}_ep{episode_db_id}.keras`).
3.  **`evaluate_strategy.py` Modifications:**
    *   Uses `test_start_date` and `test_end_date` from the config's `data_params` section for fetching data and backtesting.
    *   Uses `benchmark_ticker` from `evaluation_params` for benchmark comparison.
    *   Ensures the `transaction_cost_pct` specified in the config's `env_params` is correctly applied during the backtest simulation (verify/update `TradingEnv` if needed).
    *   Calculates and reports the following metrics (update `calculate_metrics` and potentially `metrics_calculator.py`):
        *   Total Cumulative Return (%)
        *   Benchmark (SPY) Total Cumulative Return (%)
        *   Annualized Sharpe Ratio (using `risk_free_rate` from config)
        *   Max Drawdown (%)
        *   Sortino Ratio
        *   Annualized Volatility (%)
        *   Alpha (vs. benchmark)
        *   Beta (vs. benchmark)
        *   Total Number of Trades
        *   Average Annual Trades (calculated based on test period duration and total trades)
    *   The evaluation output (console and JSON) clearly compares Agent vs Benchmark for key metrics.
    *   The evaluation output checks if objectives are met: Sharpe > 0.5, Return > Benchmark Return, Avg Annual Trades >= `required_annual_trades` (from config).
    *   Saves evaluation results JSON using `experiment_id` (e.g., `evaluation_results_{experiment_id}.json`).
    *   *(Optional Bonus)* Generates and saves a simple equity curve plot comparing Agent vs Benchmark (e.g., `equity_curve_{experiment_id}.png`).
4.  **`reinforcestrategycreator/trading_environment.py` Modifications:**
    *   Verify that transaction costs can be parameterized (e.g., during `__init__`) and are applied correctly per trade based on `transaction_cost_pct`. Implement if missing.
    *   Ensure the `info` dictionary returned by `step` contains sufficient detail to count trades accurately in `evaluate_strategy.py`.
5.  **`reinforcestrategycreator/metrics_calculator.py` Modifications:**
    *   Add functions to calculate Sortino Ratio, Annualized Volatility, Alpha, and Beta. These typically require daily/periodic returns of both the agent and the benchmark.
    *   Add a function to calculate Total Trades and Average Annual Trades (needs trade list or portfolio value series with dates).

# Checklist

- [âœ…] Add `--config` argument parsing to `train.py` and `evaluate_strategy.py`.
- [âœ…] Implement config loading logic in both scripts.
- [âœ…] Modify `train.py` data fetching to use `train_start_date`, `train_end_date`.
- [âœ…] Modify `train.py` model saving to include `experiment_id`.
- [âœ…] Modify `evaluate_strategy.py` data fetching to use `test_start_date`, `test_end_date`.
- [âœ…] Modify `evaluate_strategy.py` to use `benchmark_ticker` from config.
- [âœ…] Verify/Implement parameterized `transaction_cost_pct` in `TradingEnv`. (Verified as existing and correctly used)
- [âœ…] Add Sortino Ratio calculation to `metrics_calculator.py` and `evaluate_strategy.py`.
- [âœ…] Add Annualized Volatility calculation to `metrics_calculator.py` and `evaluate_strategy.py`.
- [âœ…] Add Alpha calculation to `metrics_calculator.py` and `evaluate_strategy.py`.
- [âœ…] Add Beta calculation to `metrics_calculator.py` and `evaluate_strategy.py`.
- [âœ…] Add Trade Count / Annualized Trade calculation and reporting to `evaluate_strategy.py`.
- [âœ…] Update `evaluate_strategy.py` reporting to include all new metrics and objective checks.
- [âœ…] Modify `evaluate_strategy.py` results saving to include `experiment_id`.
- [ ] (Optional) Add equity curve plotting to `evaluate_strategy.py`.
- [âœ…] Ensure all code is well-commented and follows project standards.

# Notes & Logs
*   This refactoring is crucial for enabling the structured optimization loop requested by the user.
*   Pay close attention to data handling (dates, returns) required for the new metric calculations.
*   Consider creating a new git branch `feature/rl-optimization-workflow` for these changes.