+++
id = "TASK-CMD-20250506-191200"
title = "Iterative RL Agent Performance Optimization Loop (vs SPY)"
status = "üü° To Do" # Options: üü° To Do, üü† In Progress, üü¢ Done, üî¥ Blocked, ‚ö™ Hold
type = "üåü Feature" # Options: üåü Feature, üêû Bug, üõ†Ô∏è Chore, üß™ Test, üìñ Documentation, ‚ùì Question, ü§î Research, ‚ö†Ô∏è Issue
priority = "High" # Options: Critical, High, Medium, Low
created_date = "2025-05-06"
updated_date = "2025-05-06" # This will be updated by the apply_diff tool
due_date = "" # Optional
assigned_to = "roo-commander" # Mode slug
coordinator = "TASK-CMD-20250506-191200" # Self or overseeing task ID
# effort = "Large" # Optional: Small, Medium, Large, XL
# complexity = "High" # Optional: Low, Medium, High
tags = ["rl", "optimization", "spy-benchmark", "iterative-process", "trading-agent", "performance"]
related_docs = [
    "TASK-PYTHON-20250506-005600" # Tuning investigation
]
# --- Sub-Tasks (Optional) ---
sub_tasks = [
  "TASK-DEVPT-20250506-191500", # Evaluation script task
  "TASK-TRAIN-20250506-193200", # Iteration 1 Training
  "TASK-EVAL-20250506-210600",  # Iteration 1 Evaluation
  "TASK-ANALYSIS-20250506-213500", # Iteration 1 Analysis & Iteration 2 Param Proposal
  "TASK-IMPL-20250506-215000",     # Iteration 2 Parameter Implementation
  "TASK-GIT-20250506-215500",      # Iteration 2 Git Push
  "TASK-TRAIN-ITER2-20250506-215700" # Iteration 2 Training
]
# --- Git Context (Optional) ---
# branch = "feature/rl-strategy-enhancements"
# commit_hash = ""
# --- User Story (Optional for Features) ---
# user_story = "As a trading strategist, I want an automated loop to iteratively train and evaluate an RL agent, aiming for performance comparable to the SPY benchmark, so that I can efficiently discover optimized trading strategies."
+++

# Description

This task manages an iterative, potentially overnight, process to improve the trading performance of the RL agent on the `feature/rl-strategy-enhancements` branch. The goal is to achieve performance comparable to a SPY benchmark (2020-01-01 to 2023-12-31) across three key metrics: Sharpe Ratio, Total Return %, and Max Drawdown.

**The Iterative Loop:**

1.  **Develop Evaluation Script (Initial Step):** Create a new script (`evaluate_strategy.py`) to:
    *   Load a trained model checkpoint.
    *   Backtest on the period 2020-01-01 to 2023-12-31.
    *   Calculate Sharpe Ratio, Total Return %, and Max Drawdown for the agent.
    *   Fetch SPY data for the same period.
    *   Calculate Sharpe Ratio, Total Return %, and Max Drawdown for SPY.
    *   Output these metrics for comparison.
    *   *(This will be delegated as a sub-task)*
2.  **Train Agent:** Execute `train.py`. Start with 20 episodes per iteration, adapting as needed based on progress and analysis.
3.  **Evaluate Performance:** Run the `evaluate_strategy.py` script using the newly trained model.
4.  **Compare with SPY Benchmark:** Analyze the output from the evaluation script, comparing the agent's Sharpe Ratio, Total Return %, and Max Drawdown against SPY's.
5.  **Decision Point:**
    *   **If Satisfactory:** Performance is comparable or better than SPY on all three metrics. Stop the loop, log success.
    *   **If Not Satisfactory:** Proceed to parameter adjustment.
6.  **Parameter Change Strategy (Heuristic):**
    *   Analyze the run's performance metrics, training logs, and previous changes.
    *   Consider recommendations from `TASK-PYTHON-20250506-005600`.
    *   Decide which parameters to change (e.g., hyperparameters in `train.py`, environment settings, number of training episodes for next run).
7.  **Implement Changes:** Modify the relevant files (e.g., `train.py`).
8.  **Commit Changes:** Commit changes to the `feature/rl-strategy-enhancements` branch with clear, descriptive messages (Conventional Commits standard, referencing this Task ID).
9.  **Push Changes:** Push changes to the remote repository.
10. **Repeat:** Go back to Step 2 (Train Agent).

# Acceptance Criteria

*   The iterative loop is successfully executed.
*   The RL agent's trading performance (Sharpe Ratio, Total Return %, Max Drawdown) on the test period (2020-01-01 to 2023-12-31) is comparable to, or better than, the SPY benchmark for the same period.
*   All significant steps, decisions, parameter changes, and evaluation results are logged within this task or linked documents.
*   Final optimized parameters and model are committed and pushed.

# Checklist

- [ ] **Phase 1: Setup**
    - [‚úÖ] Define and create master MDTM task (this file). (Done 2025-05-06 19:12:00)
    - [‚úÖ] Create and delegate sub-task for `evaluate_strategy.py` development. (TASK-DEVPT-20250506-191500) (Delegated 2025-05-06 19:15:00)
    - [‚úÖ] `evaluate_strategy.py` script developed, tested, and merged/available. (Development reported complete by dev-python 2025-05-06 ~19:30:00, tested and confirmed working 2025-05-06 ~21:31 via TASK-EVAL-20250506-210600)
- [ ] **Phase 2: Iterative Loop Execution (Repeat as needed)**
    - [‚úÖ] Iteration 1: Set/Adjust training episodes (Start: 20) (Set for TASK-TRAIN-20250506-193200)
    - [‚úÖ] Iteration 1: Execute `train.py` (Completed via TASK-TRAIN-20250506-193200 on 2025-05-06 ~21:04)
    - [‚úÖ] Iteration 1: Execute `evaluate_strategy.py` (Completed via TASK-EVAL-20250506-210600 on 2025-05-06 ~21:31)
    - [‚úÖ] Iteration 1: Compare Agent vs SPY metrics. (Done as part of TASK-EVAL-20250506-210600)
    - [‚úÖ] Iteration 1: Log metrics and comparison. (Logged below and in TASK-EVAL-20250506-210600)
    - [‚úÖ] Iteration 1: Decision: Satisfactory? (Performance is NOT satisfactory, logged 2025-05-06 ~21:31)
    - [‚úÖ] Iteration 1: Decide parameter changes (heuristic) (Completed via TASK-ANALYSIS-20250506-213500 on 2025-05-06 ~21:47)
    - [‚úÖ] Iteration 1: Log decided changes. (Logged below 2025-05-06 ~21:47)
    - [‚úÖ] Iteration 1: Implement parameter changes (Completed via TASK-IMPL-20250506-215000 for Iteration 2 params on 2025-05-06 ~21:52)
    - [‚úÖ] Iteration 1: Commit changes (branch: `feature/rl-strategy-enhancements`, Refs: `TASK-CMD-20250506-191200`). (Done as part of TASK-IMPL-20250506-215000)
    - [‚úÖ] Iteration 1: Push changes (Completed via TASK-GIT-20250506-215500 for Iteration 2 changes on 2025-05-06 ~21:54).
    - [ ] Iteration 2: Set/Adjust training episodes (1000 episodes, params from TASK-ANALYSIS-20250506-213500)
    - [ ] Iteration 2: Execute `train.py` (Delegated as TASK-TRAIN-ITER2-20250506-215700)
    - [ ] Iteration 2: Execute `evaluate_strategy.py`.
    - [ ] Iteration 2: Compare Agent vs SPY metrics.
    - [ ] Iteration 2: Log metrics and comparison.
    - [ ] Iteration 2: Decision: Satisfactory? (If yes, proceed to Finalization)
    - [ ] Iteration 2: Decide parameter changes (heuristic).
    - [ ] Iteration 2: Log decided changes.
    - [ ] Iteration 2: Implement parameter changes.
    - [ ] Iteration 2: Commit changes (branch: `feature/rl-strategy-enhancements`, Refs: `TASK-CMD-20250506-191200`).
    - [ ] Iteration 2: Push changes.
- [ ] **Phase 3: Finalization**
    - [ ] Performance goal achieved.
    - [ ] Log final metrics and parameters.
    - [ ] Ensure final code and model are committed and pushed.
    - [ ] Report completion.

# Notes & Logs

*   **2025-05-06 19:12:00 (Roo Commander):** Master MDTM task created. Clarifications received from user:
    *   Benchmark: Sharpe Ratio, Total Return %, Max Drawdown equally. Period: 2020-2023.
    *   Evaluation: Develop a new, dedicated script.
    *   Params Change: Heuristic approach based on run analysis.
    *   Training Episodes: Start with 20, adapt based on progress.
*   **2025-05-06 19:15:00 (Roo Commander):** Created sub-task `TASK-DEVPT-20250506-191500` for `evaluate_strategy.py` development. Delegated to `dev-python`.
*   **2025-05-06 19:30:00 (Roo Commander):** `dev-python` reported completion of `TASK-DEVPT-20250506-191500`. The `evaluate_strategy.py` script is developed. Testing of this script (and final completion of its MDTM checklist) will occur after the first training iteration.
*   **2025-05-06 19:32:00 (Roo Commander):** Created sub-task `TASK-TRAIN-20250506-193200` for Iteration 1 training (20 episodes). Delegated to `dev-python`.
*   **2025-05-06 21:04:00 (Roo Commander):** `dev-python` reported completion of `TASK-TRAIN-20250506-193200`. Iteration 1 training (20 episodes) complete. Run ID: `RUN-SPY-20250506181240-6dc6a496`. Model saved to `models/episode_20_model.keras`.
*   **2025-05-06 21:06:00 (Roo Commander):** Created sub-task `TASK-EVAL-20250506-210600` for Iteration 1 evaluation. Delegated to `dev-python`.
*   **2025-05-06 21:31:00 (Roo Commander):** `dev-python` reported completion of `TASK-EVAL-20250506-210600`. Iteration 1 evaluation complete.
    *   **RL Agent (models/episode_20_model.keras):**
        *   Total Return: -0.02%
        *   Sharpe Ratio: 0.00
        *   Max Drawdown: 3.01%
    *   **SPY Benchmark:**
        *   Total Return: 55.81%
        *   Sharpe Ratio: 0.04
        *   Max Drawdown: 33.72%
    *   Agent underperformed. Results saved to `.ruru/tasks/RL_Agent_Optimization_Loop/Iteration1/evaluation_results_iter1.json`.
*   **2025-05-06 21:35:00 (Roo Commander):** Created sub-task `TASK-ANALYSIS-20250506-213500` for Iteration 1 analysis and Iteration 2 parameter proposal. Delegated to `dev-python`.
*   **2025-05-06 21:47:00 (Roo Commander):** `dev-python` reported completion of `TASK-ANALYSIS-20250506-213500`. Iteration 1 analysis complete.
    *   **Proposed Changes for Iteration 2 (documented in TASK-ANALYSIS-20250506-213500):**
        *   `TRAINING_EPISODES = 1000`
        *   `AGENT_GAMMA = 0.99`
        *   `AGENT_EPSILON_DECAY = 0.9999`
        *   `AGENT_TARGET_UPDATE_FREQ = 100`
        *   `ENV_DRAWDOWN_PENALTY = 0.05`
        *   `ENV_TRADING_PENALTY = 0.005`
        *   `TradingEnv` initialization: `use_sharpe_ratio=True`
*   **2025-05-06 21:50:00 (Roo Commander):** Created sub-task `TASK-IMPL-20250506-215000` for implementing Iteration 2 parameter changes. Delegated to `dev-python`.
*   **2025-05-06 21:52:00 (Roo Commander):** `dev-python` reported completion of `TASK-IMPL-20250506-215000`. Parameter changes for Iteration 2 implemented and committed to `feature/rl-strategy-enhancements`.
*   **2025-05-06 21:55:00 (Roo Commander):** Created sub-task `TASK-GIT-20250506-215500` for pushing Iteration 2 changes. Delegated to `dev-git`.
*   **2025-05-06 21:54:00 (Roo Commander):** `dev-git` reported completion of `TASK-GIT-20250506-215500`. Iteration 2 parameter changes pushed to remote `feature/rl-strategy-enhancements`. Iteration 1 is now complete.
*   **2025-05-06 21:57:00 (Roo Commander):** Created sub-task `TASK-TRAIN-ITER2-20250506-215700` for Iteration 2 training (1000 episodes with new parameters).
*   Next step: Delegate `TASK-TRAIN-ITER2-20250506-215700` to `dev-python`.