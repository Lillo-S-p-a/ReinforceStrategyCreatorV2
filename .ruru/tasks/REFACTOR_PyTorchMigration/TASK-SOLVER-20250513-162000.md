+++
# --- MDTM Task: Chore ---
id = "TASK-SOLVER-20250513-162000" # Unique Task ID: TASK-[MODE_PREFIX]-[YYYYMMDD-HHMMSS]
title = "Refactor RLlib Integration for PyTorch Compatibility (Post-Migration)"
status = "‚ö™ Blocked"  # Options: üü° To Do, üü† In Progress, üü¢ Done, ‚ö™ Blocked, üî¥ Cancelled, üü£ Review
type = "‚öôÔ∏è Chore"     # Options: üåü Feature, üêû Bug, ‚öôÔ∏è Chore, üìñ Documentation, üß™ Test, üí° Spike
priority = "üî¥ Highest" # Options: üî¥ Highest, üü† High, üü° Medium, üü¢ Low
created_date = "2025-05-13"
updated_date = "2025-05-14"
# due_date = "YYYY-MM-DD" # Optional
# estimated_effort = "X hours/days" # Optional: e.g., "4 hours", "2 days"
# actual_effort = "X hours/days" # Optional: Filled upon completion
assigned_to = "dev-solver" # Mode slug
# reported_by = "User" # Optional: User, another mode, or system
coordinator = "TASK-CMD-20250513-153700" # Coordinator's Task ID
# related_tasks = [] # Optional: List of related MDTM task IDs
# related_docs = [] # Optional: List paths/URLs to related documents/specs
# parent_task = "" # Optional: MDTM Task ID of parent task
sub_tasks = ["TASK-SOLVER-20250514-115000"] # Optional: List of MDTM Task IDs for sub-tasks
tags = ["rllib", "pytorch", "tensorflow-migration", "refactor", "callbacks", "api-adaptation", "bugfix"]
template_schema_doc = ".ruru/templates/toml-md/03_mdtm_chore.README.md"

# --- Chore Specific Fields ---
# impact_areas = ["performance", "stability", "maintainability"] # Optional: e.g., performance, stability, security, maintainability, ci-cd
# reason = "Technical debt, dependency update, code cleanup, process improvement" # Brief reason for the chore

# --- Context for AI ---
# Provide specific context to help AI understand and execute the task
# ai_context_files = [ # Optional: List of file paths relevant to this task
#    "path/to/relevant/file1.py",
#    "path/to/relevant/config.json"
# ]
# ai_context_notes = """ # Optional: Free-form notes for AI
# - Focus on X, Y, Z.
# - Be aware of A, B, C.
# """
ai_context_files = [
    "reinforcestrategycreator/callbacks.py",
    "train.py",
    "callbacks_debug.log" # Assuming this will be populated with useful logs from the next run
]
ai_context_notes = """
The core issue is that `reinforcestrategycreator/callbacks.py` is not correctly logging episode data to the database after a project migration from TensorFlow to PyTorch.
RLlib's new API stack is in use.
The `episode` object passed to callbacks (e.g., `on_episode_start`, `on_episode_end`) seems to be of type `SingleAgentEpisode`.
An `AttributeError` occurred when trying to access `episode.episode_id`; it's likely `episode.id_` should be used.
The `on_episode_end` callback was not being reliably triggered or logged in previous debugging attempts, possibly due to errors in `on_episode_start` or incorrect data access.
The goal is to refactor the callback logic to correctly interface with RLlib's PyTorch backend and new API stack, ensuring all necessary episode metrics (final portfolio value, PnL, trades, etc.) are captured and stored.
Pay close attention to how data is extracted from the `episode` object in `on_episode_end` (e.g., using `episode.last_info_for()`, `episode.custom_data`, `episode.total_reward`, `episode.length`).
"""
+++

# Refactor RLlib Integration for PyTorch Compatibility

## 1. Description üìù

The project recently migrated from TensorFlow to PyTorch. This has led to issues in the RLlib integration, specifically within `reinforcestrategycreator/callbacks.py`. The `DatabaseLoggingCallbacks` class is failing to correctly log episode data (like final portfolio value, PnL, trades) to the PostgreSQL database.

Symptoms observed include:
*   `AttributeError: 'SingleAgentEpisode' object has no attribute 'episode_id'` in `on_episode_start`.
*   The `on_episode_end` callback method appears not to be called or fails early, as indicated by missing logs in `callbacks_debug.log`.
*   Database entries for episodes are created but not completed (missing `end_time` and metrics).

This task involves refactoring the `DatabaseLoggingCallbacks` and potentially related parts of the RLlib setup in `train.py` to ensure correct operation with RLlib's new API stack and PyTorch backend.

## 2. Reason for Chore üõ†Ô∏è

This refactor is necessary to fix a critical bug in data logging, which is essential for tracking training progress and model performance. The bug stems from API incompatibilities and changes in object structures after the TensorFlow to PyTorch migration.

## 3. Acceptance Criteria ‚úÖ

*   [ ] `reinforcestrategycreator/callbacks.py` correctly uses `episode.id_` (or the appropriate attribute) to access the RLlib episode identifier.
*   [ ] The `on_episode_start` callback executes without errors and correctly logs the start of an episode to the database.
*   [ ] The `on_episode_end` callback is reliably called at the end of each episode.
*   [ ] The `callbacks_debug.log` file shows detailed logs from `on_episode_end`, including the inspection of the `episode` object's attributes.
*   [ ] All relevant episode metrics (final portfolio value, PnL, total reward, episode length, custom metrics like Sharpe ratio if available) are accurately extracted from the `episode` object (or related sources like `episode.last_info_for()`, `env` state) within `on_episode_end`.
*   [ ] Completed trades are correctly extracted and logged to the database via `on_episode_end`.
*   [ ] Database entries in the `episodes` table are correctly updated with `end_time` and all relevant metrics upon episode completion.
*   [ ] No `AttributeError` or `TypeError` related to RLlib API usage occurs within the callbacks.
*   [ ] The solution is compatible with RLlib's new API stack and PyTorch.

## 4. Proposed Changes / Implementation Plan (Optional) üí°

1.  **Investigate `episode` Object:** Thoroughly analyze the logs from `callbacks_debug.log` (after the next successful training run with corrected `on_episode_start`) to understand the structure of the `episode` object passed to `on_episode_end` in the PyTorch/new API context.
2.  **Correct Attribute Access:** Modify `callbacks.py` to use the correct attributes and methods for accessing episode ID (likely `episode.id_`), total reward, length, custom data, and last step information (`episode.last_info_for()`).
3.  **Environment Data:** Determine the most reliable way to access environment-specific data like `portfolio_value` and `initial_balance` at the end of an episode (e.g., via `episode.last_info_for()` or by ensuring the `env` object passed to callbacks is the correct, non-reset instance).
4.  **Custom Metrics:** Ensure custom metrics (Sharpe, drawdown, win rate) populated by the `TradingEnv` are correctly passed through and accessible in `on_episode_end` via `episode.custom_metrics`.
5.  **Testing:** After refactoring, run `train.py` and verify:
    *   `callbacks_debug.log` shows correct data extraction.
    *   The `episodes` and `trades` tables in the database are populated correctly.
    *   The `check_episodes.py` script reports a high completion rate.

## 5. Potential Risks & Mitigation (Optional) üöß

*   **RLlib API Nuances:** The new RLlib API stack might have further subtleties. Mitigation: Refer to the latest RLlib documentation for PyTorch and consult examples.
*   **Data Availability:** Information previously available directly on the `env` object might now only be accessible through `episode.last_info_for()` or `episode.custom_metrics`. Mitigation: Prioritize these access methods.

## 6. Checklist / Sub-Tasks üìã

*   [‚úÖ] Correct `episode.episode_id` to `episode.id_` in `on_episode_start` and `on_episode_end` logging.
*   [ ] Run `train.py` to populate `callbacks_debug.log` with `on_episode_end` details.
*   [ ] Analyze `callbacks_debug.log` to confirm `on_episode_end` is called and to understand `episode` object structure.
*   [ ] Refactor data extraction in `on_episode_end` for `final_portfolio_value`, `initial_portfolio_value`, `pnl`, `total_reward`, `length`, `sharpe_ratio`, `max_drawdown`, `win_rate`.
*   [ ] Refactor extraction of completed trades.
*   [ ] Verify database updates for `episodes` and `trades` tables.
*   [ ] Test thoroughly by running `train.py` and checking logs/database.
*   [ ] Run `check_episodes.py` to confirm a high completion rate.

## Notes / Logs üìì

*(Specialist will add notes here during task execution)*

2025-05-14:
- Corrected `episode.episode_id` to `episode.id_` in `reinforcestrategycreator/callbacks.py` (on_episode_start).
- Ran `train.py`. Script was manually stopped.
- `callbacks_debug.log` only shows initialization messages. No logs from `on_episode_start` or `on_episode_end` were generated, indicating these methods might not be called or are erroring out before logging their entry.
- **Blocker Identified (2025-05-14):** Progress on this task is blocked because `on_episode_start` logs are not appearing. A new sub-task `TASK-SOLVER-20250514-115000` ("Debug: Investigate Missing `on_episode_start` Logs in Callbacks") has been created to address this. This parent task will resume once the sub-task is completed and `on_episode_start` logs are available for analysis.