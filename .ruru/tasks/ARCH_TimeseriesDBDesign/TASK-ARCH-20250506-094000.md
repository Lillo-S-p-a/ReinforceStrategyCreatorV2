+++
id = "TASK-ARCH-20250506-094000"
title = "Design Timeseries Database for Historical Market Data"
status = "ðŸŸ¢ Done"
type = "ðŸ›ï¸ Architecture Design"
created_date = "2025-05-06"
updated_date = "2025-05-06"
assigned_to = "core-architect"
coordinator = "TASK-CMD-20250506-094000" # Roo Commander Session Reference
priority = "High"
complexity = "Medium"
estimated_effort = "4h"
related_tasks = ["TASK-PYTHON-20250506-090300"] # This new DB will unblock the Python debugging
tags = ["database", "architecture", "timeseries", "postgresql", "docker", "market-data", "schema-design", "timescaledb"]
target_branch = "feature/timeseries-db"
+++

# Design Timeseries Database for Historical Market Data

## 1. Description

The project requires a persistent storage solution for historical market data (OHLCV, technical indicators) to avoid repeated downloads from external APIs (e.g., Yahoo Finance) and mitigate rate-limiting issues. This will also improve data access performance for training RL agents and other analyses.

This task involves designing the database schema and the infrastructure setup for this new data store.

**Key Requirements:**
1.  The database **MUST** be a new, separate PostgreSQL instance running in its own Docker container.
2.  This PostgreSQL instance **MUST** utilize a suitable time-series extension (e.g., TimescaleDB) for efficient storage and querying of time-series data.
3.  Design a database schema capable of storing:
    *   Ticker symbol (e.g., 'SPY', 'AAPL').
    *   Timestamp (datetime with timezone, appropriate precision for financial data).
    *   Open, High, Low, Close prices (numeric types with sufficient precision).
    *   Volume (integer or long integer).
    *   Adjusted Close (if applicable and available from source).
    *   Optionally, common pre-calculated technical indicators (e.g., SMA(20), EMA(12), RSI(14), MACD line, MACD signal, MACD histogram). Consider if these should be in the same table, separate tables linked by ticker/timestamp, or stored as JSON/arrays if the DB supports it efficiently.
4.  The schema should be optimized for queries common in financial analysis:
    *   Retrieving all data for a specific ticker within a date range.
    *   Retrieving specific columns (e.g., just 'close' and 'volume') for a ticker.
    *   Efficiently joining price data with indicator data if stored separately.
    *   Time-based aggregations (e.g., daily to weekly/monthly).
5.  Provide specifications for the Docker setup (e.g., a `docker-compose.yml` service definition or a Dockerfile) for this new PostgreSQL/TimescaleDB container. Include considerations for data persistence (volumes).
6.  Outline how this new database service will integrate with the existing application infrastructure (e.g., environment variables for connection strings, network accessibility for other services like `data_fetcher.py`).
7.  Briefly consider data ingestion strategies (e.g., a separate Python script for initial bulk load and subsequent incremental updates).

## 2. Acceptance Criteria

*   A clear database schema design document is produced. This should include:
    *   Table definitions (column names, data types, constraints like NOT NULL).
    *   Primary keys, foreign keys (if any), and indexing strategies (especially on timestamp and ticker).
    *   Rationale for schema choices, particularly regarding indicator storage.
*   The schema supports storage of OHLCV data and potentially technical indicators for multiple tickers.
*   Specifications for setting up a new PostgreSQL Docker container with a time-series extension (e.g., TimescaleDB) are provided (e.g., `docker-compose.yml` snippet).
*   High-level integration points with the existing application are outlined.
*   The design considers efficiency for time-series queries.

## 3. Checklist

*   [âœ…] Analyze requirements for historical data storage, including specific data points (OHLCV, common indicators).
*   [âœ…] Research and confirm the choice of PostgreSQL time-series extension (e.g., TimescaleDB) and its implications for schema design and Docker setup. (Confirmed TimescaleDB)
*   [âœ…] Design the table structure(s) for OHLCV and indicator data. (Single hypertable `market_data` proposed)
*   [âœ…] Define primary keys, foreign keys (if applicable), optimal indexing strategies (e.g., composite indexes on ticker and time), and appropriate data types. (Defined in schema DDL)
*   [âœ…] Create Docker configuration (e.g., `docker-compose.yml` service definition) for the new PostgreSQL/TimescaleDB container, including volume mapping for data persistence. (Snippet provided)
*   [âœ…] Document the proposed schema (e.g., DDL, ERD sketch) and Docker setup. (Added to Logs/Notes section)
*   [âœ…] Outline a high-level data ingestion strategy (initial load, updates). (Outlined in Logs/Notes section)
*   [âœ…] Outline how other services will connect to and query this new database. (Outlined in Logs/Notes section)
*   [ ] Submit design for review. (Ready for submission)

## 4. Logs / Notes

*(core-architect will add notes, decisions, and design details here)*

**Design Document (2025-05-06)**

**1. Database Schema Design**

*   **Rationale:** A single hypertable is chosen for simplicity and query performance, storing both OHLCV and common technical indicators. This assumes a relatively fixed set of indicators will be stored initially. If indicator flexibility becomes a major requirement later, migrating indicators to a separate table or JSONB column can be considered. `TIMESTAMPTZ` is used for time to handle timezones correctly. `NUMERIC` provides arbitrary precision suitable for financial data. `BIGINT` is used for volume. TimescaleDB is selected as the time-series extension.
*   **Table:** `market_data` (This will be converted into a TimescaleDB hypertable)

```sql
-- Main table for storing OHLCV and technical indicators
CREATE TABLE market_data (
    timestamp TIMESTAMPTZ NOT NULL,
    ticker TEXT NOT NULL,
    open NUMERIC,
    high NUMERIC,
    low NUMERIC,
    close NUMERIC,
    adjusted_close NUMERIC,
    volume BIGINT,
    -- Common Technical Indicators (add/remove as needed)
    sma_20 NUMERIC,
    ema_12 NUMERIC,
    rsi_14 NUMERIC,
    macd_line NUMERIC,
    macd_signal NUMERIC,
    macd_hist NUMERIC
    -- Add other indicators here if required
);

-- Create TimescaleDB hypertable, partitioning by time
-- Adjust chunk_time_interval based on expected data frequency and volume (e.g., '1 day', '7 days')
SELECT create_hypertable('market_data', 'timestamp', chunk_time_interval => INTERVAL '7 days');

-- Create unique index for data integrity (ticker + timestamp combination must be unique)
-- This also serves as the primary query index for filtering by ticker and time
CREATE UNIQUE INDEX ix_ticker_timestamp ON market_data (ticker, timestamp DESC);

-- Optional: Create indexes on individual indicators if frequently queried directly
-- CREATE INDEX ix_sma_20 ON market_data (sma_20) WHERE sma_20 IS NOT NULL;
-- CREATE INDEX ix_rsi_14 ON market_data (rsi_14) WHERE rsi_14 IS NOT NULL;

-- Optional: Create index on ticker alone if querying all data for a ticker often without time filters
-- CREATE INDEX ix_ticker ON market_data (ticker);

```

**2. Docker Configuration (`docker-compose.yml` Snippet)**

*   **Rationale:** Uses the official TimescaleDB image which includes PostgreSQL. A named volume (`timescaledb_data`) ensures data persistence across container restarts. Environment variables configure the database user, password, and name. Port 5432 is exposed internally, mapped to 5433 externally.

```yaml
services:
  timescaledb:
    image: timescale/timescaledb:latest-pg16 # Use appropriate PostgreSQL version tag
    container_name: timescaledb_market_data
    environment:
      POSTGRES_USER: ${TIMESCALEDB_USER:-user} # Use environment variables or defaults
      POSTGRES_PASSWORD: ${TIMESCALEDB_PASSWORD:-password}
      POSTGRES_DB: ${TIMESCALEDB_DB:-marketdata}
    ports:
      - "5433:5432" # Expose on 5433 host-side to avoid conflict if another PG runs on 5432
    volumes:
      - timescaledb_data:/var/lib/postgresql/data # Persistent data volume
    networks:
      - app-network # Ensure it's on the same network as other services

volumes:
  timescaledb_data:

networks:
  app-network:
    driver: bridge
```
*(Note: Ensure the `.env` file or environment variables provide `TIMESCALEDB_USER`, `TIMESCALEDB_PASSWORD`, `TIMESCALEDB_DB` or adjust defaults. Ensure other services needing access are also on `app-network`)*

**3. Integration Outline**

*   **Connection:** Other services (e.g., `data_fetcher.py`, `reinforcestrategycreator`, `dashboard`) will connect using a standard PostgreSQL connection string via libraries like `psycopg2` or `SQLAlchemy`.
*   **Connection String:** `postgresql://${TIMESCALEDB_USER}:${TIMESCALEDB_PASSWORD}@timescaledb:5432/${TIMESCALEDB_DB}` (assuming services are on the same Docker network `app-network`, using the service name `timescaledb` as the hostname).
*   **Configuration:** Connection details should be managed via environment variables loaded by the application components.

**4. Data Ingestion Strategy (High-Level)**

*   **Initial Load:** A dedicated Python script should be created to fetch historical data for required tickers (e.g., using `yfinance`) and perform a bulk insert into the `market_data` table. Using PostgreSQL's `COPY FROM STDIN WITH CSV` via `psycopg2`'s `copy_expert` or `copy_from` is highly recommended for performance.
*   **Incremental Updates:** The same script (or a modified version) can be run periodically (e.g., daily) to fetch the latest data and insert it. Use `INSERT ... ON CONFLICT (ticker, timestamp) DO NOTHING` or `DO UPDATE` to handle potential overlaps or corrections if needed.
*   **Indicator Calculation:** Decide whether indicators are calculated *before* ingestion (by the Python script) or *after* ingestion (using SQL functions or triggers within the database). Pre-calculation in Python is often simpler to manage.