+++
id = "TASK-FIX-20250513-185800"
title = "Investigate and Resolve Training Run Warnings and Callback Issues"
status = "‚ö™ Blocked"
type = "üêû Bug"
priority = "‚ñ∂Ô∏è Medium"
created_date = "2025-05-13"
updated_date = "2025-05-14"
assigned_to = "dev-fixer"
reporter = "roo-commander"
related_docs = ["callbacks_debug.log", "run_train.sh"]
tags = ["training", "rllib", "callbacks", "cuda", "cudnn", "cublas", "logging", "ray", "gpu"]
template_schema_doc = ".ruru/templates/toml-md/02_mdtm_bug.README.md"
+++

# Investigate and Resolve Training Run Warnings and Callback Issues

## Description ‚úçÔ∏è

Multiple warnings and potential logic issues were observed during and after the RLlib training run (`RLlibRUN-SPY-20250513165309-dffdcb6c`), initiated by `bash run_train.sh`.

*   **What is the problem?**
    1.  **GPU-related warnings (Terminal):**
        *   `Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered`
        *   `Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered`
        *   `computation placer already registered. Please check linkage and avoid linking the same target more than once.`
    2.  **Callback Issue: Repeated Episode End Logging (`callbacks_debug.log`):**
        *   `WARNING - DB Episode 1452 (RLlib ID: 0dcc297c02074e7e92ea8c49476c63c5) already has an end_time. Skipping update from _log_episode_end_data.` (occurs multiple times for the same episode).
    3.  **Callback Issue: `on_sample_end` Worker Argument (`callbacks_debug.log`):**
        *   `WARNING - on_sample_end: 'worker' argument is None.` (appears consistently, falls back to `kwargs['env_runner']`).
    4.  **Callback Issue: Could Not Find Completed Trades (`callbacks_debug.log`):**
        *   `WARNING - Could not find completed_trades via any method.` (logged for DB episode 1452).

*   **Where does it occur?**
    1.  Terminal output during `bash run_train.sh` execution.
    2.  [`callbacks_debug.log`](callbacks_debug.log) generated during the training run.
    3.  Likely involves logic within [`reinforcestrategycreator/callbacks.py`](reinforcestrategycreator/callbacks.py) and potentially the RLlib/GPU environment setup.

*   **Impact:**
    1.  Potential GPU underutilization, incorrect GPU detection, or environment instability.
    2.  Incorrect or noisy logging in callbacks, potential for redundant database operations, and performance overhead.
    3.  Possible incompatibility with RLlib API versions or incorrect callback invocation.
    4.  Potentially missing trade metrics in the database, or unclear logging if no trades occurred.

## Steps to Reproduce üö∂‚Äç‚ôÄÔ∏è

1.  Ensure the environment is set up as per the project's requirements (Python, Poetry, dependencies including RLlib, PyTorch/TensorFlow, CUDA if applicable).
2.  Execute the command: `bash run_train.sh` from the workspace root.
3.  Observe the terminal output for the GPU-related warnings.
4.  After the run completes, examine the content of [`callbacks_debug.log`](callbacks_debug.log) for the callback-specific warnings.

## Expected Behavior ‚úÖ

*   Training run proceeds without cuDNN, cuBLAS, or placer registration errors if a GPU is correctly configured and intended for use. If no GPU is intended, these errors should not appear.
*   The `_log_episode_end_data` method in callbacks should log metrics for an episode only once upon its actual completion.
*   The `on_sample_end` callback should receive all its expected arguments with correct types, or the handling of potentially missing arguments should be robust.
*   Information about completed trades should be accurately retrieved and logged, or if no trades occurred, this should be clearly and correctly indicated.

## Actual Behavior ‚ùå

*   GPU-related warnings appear in the terminal.
*   The same episode (e.g., DB Episode 1452) has its end logged multiple times, with warnings about it already having an end_time.
*   The `on_sample_end` callback consistently logs that the `worker` argument is `None`.
*   A warning about not finding completed trades was logged for at least one episode.

## Environment Details üñ•Ô∏è (Optional - Use if not in TOML)

*   **OS:** Linux 6.8 (from initial system information)
*   **App Version/Commit:** Current state of the repository.
*   **Key Libraries:** RLlib (version from `poetry.lock`), PyTorch/TensorFlow (version from `poetry.lock`), CUDA/cuDNN (system versions if applicable).

## Acceptance Criteria (Definition of Done) ‚úÖ

*   - [‚úÖ] Root causes for cuDNN/cuBLAS/placer warnings are identified. If GPU use is intended, warnings are resolved, and GPU utilization is confirmed. If GPU use is not intended, these warnings are suppressed or resolved.
    *   **Fix:** Removed unused `tensorflow` dependency from [`pyproject.toml`](pyproject.toml) as RLlib is configured for PyTorch. This is expected to prevent conflicting GPU component initializations. User needs to run `poetry lock && poetry install`.
*   - [‚úÖ] The logic in `_log_episode_end_data` (likely in [`reinforcestrategycreator/callbacks.py`](reinforcestrategycreator/callbacks.py)) is corrected to ensure episode end metrics are logged only once per episode, eliminating the "already has an end_time" warnings.
    *   **Fix:** Modified `_log_episode_end_data` in [`reinforcestrategycreator/callbacks.py`](reinforcestrategycreator/callbacks.py) to use `episode.custom_data["_db_logged_end"] = True` flag to prevent re-logging for an already processed episode.
*   - [‚úÖ] The `on_sample_end` callback correctly receives or robustly handles the `worker` argument, resolving the "worker argument is None" warnings. This might involve API compatibility checks for RLlib.
    *   **Fix:** Adjusted `on_sample_end` in [`reinforcestrategycreator/callbacks.py`](reinforcestrategycreator/callbacks.py) to prioritize `kwargs.get("env_runner")` (common with new RLlib API stack) and made the warning about `worker` being `None` conditional.
*   - [‚úÖ] The "Could not find completed_trades" warning is investigated. If trades should be present, the retrieval logic is fixed. If no trades occurred, the logging is clarified or confirmed as appropriate.
    *   **Fix:** Updated `_log_episode_end_data` in [`reinforcestrategycreator/callbacks.py`](reinforcestrategycreator/callbacks.py) to use `actual_env_for_value.get_completed_trades()` as a more robust fallback and clarified logging if no trades are found (which can be normal).
*   - [ ] A subsequent training run using `bash run_train.sh` shows a significant reduction or complete elimination of these specific warnings in both terminal output and [`callbacks_debug.log`](callbacks_debug.log).
*   - [ ] (Optional) Consider adding more specific debug logging within callbacks to trace argument states if issues persist.

## Implementation Notes / Root Cause Analysis üìù

*   **GPU Warnings (cuDNN, cuBLAS, placer "already registered"):**
    *   **Root Cause:** Likely caused by the presence of both `pytorch` and `tensorflow` in [`pyproject.toml`](pyproject.toml). Even though RLlib was configured for PyTorch, TensorFlow might still attempt to initialize GPU components, leading to conflicts when Ray workers also initialize PyTorch components.
    *   **Fix:** Removed the `tensorflow` dependency from [`pyproject.toml`](pyproject.toml) as it was confirmed to be unused. This should prevent conflicting initializations. The user needs to update their environment via `poetry lock && poetry install`.

*   **Callback Issue: Repeated Episode End Logging:**
    *   **Root Cause:** The `_log_episode_end_data` method was being called multiple times for the same episode (likely from both `on_episode_end` and `on_sample_end` with the new RLlib API stack). The existing check for `existing_db_ep.end_time` prevented duplicate DB writes but still resulted in warnings.
    *   **Fix:** Implemented a flag `episode.custom_data["_db_logged_end"] = True` within `_log_episode_end_data` in [`reinforcestrategycreator/callbacks.py`](reinforcestrategycreator/callbacks.py). The method now checks this flag at the beginning and skips processing if the episode end has already been logged by the callback instance, thus preventing the warning.

*   **Callback Issue: `on_sample_end` Worker Argument `None`:**
    *   **Root Cause:** The `on_sample_end` callback in the new RLlib API stack often provides the environment runner via `kwargs["env_runner"]` rather than the direct `worker` argument. The existing code correctly fell back to `env_runner` but logged a warning about `worker` being `None` unconditionally.
    *   **Fix:** Modified `on_sample_end` in [`reinforcestrategycreator/callbacks.py`](reinforcestrategycreator/callbacks.py) to first check for and use `kwargs.get("env_runner")`. If `env_runner` is not found, it then checks the `worker` argument. The warning is now conditional, only appearing if neither is available.

*   **Callback Issue: Could Not Find Completed Trades:**
    *   **Root Cause:** The original logic for retrieving `completed_trades` in `_log_episode_end_data` relied on `episode.get_infos()[-1]` or direct access to `_completed_trades` on the environment. This might not always capture trades if called at an intermediate point or if the environment instance wasn't correctly identified.
    *   **Fix:** Enhanced the trade retrieval logic in `_log_episode_end_data` in [`reinforcestrategycreator/callbacks.py`](reinforcestrategycreator/callbacks.py). It now attempts to use `actual_env_for_value.get_completed_trades()` (the public getter in `TradingEnv`) as a more reliable fallback. Additionally, the logging message when no trades are found has been clarified to indicate that this can be a normal scenario.

## AI Prompt Log ü§ñ (Optional)

*   (To be filled by `dev-fixer`)

## Review Notes üëÄ (For Reviewer)

*   (To be filled by `dev-fixer` or reviewer)
*   **Update 2025-05-14 (Roo Commander):** While individual warning fixes in this task were applied, the core data logging issue persists after user validation. This task is now considered blocked pending the outcome of `TASK-SOLVER-20250513-162000`, which addresses deeper callback refactoring for PyTorch compatibility. The unchecked acceptance criterion regarding a successful training run without warnings and with correct data logging is dependent on that task.

## Key Learnings üí° (Optional - Fill upon completion)

*   (To be filled by `dev-fixer`)