+++
# --- MDTM Task ---
id = "TASK-BE-LEAD-20250504000300"
title = "Implement Backend for Performance Metrics"
status = "🟡 To Do" # Options: 🟡 To Do, 🟠 In Progress, 🟢 Done, ⚪ Blocked, 🟣 Review
created_date = "2025-05-04"
updated_date = "2025-05-04"
type = "🌟 Feature" # Options: 🌟 Feature, 🐞 Bug, 🛠️ Chore, 🧪 Test, 📚 Doc, 📐 Design, ❓ Question, ⚠️ Issue
priority = "🔴 High" # Options: 🔴 High, 🟠 Medium, 🟡 Low
assigned_to = "lead-backend" # Mode slug
coordinator = "TASK-CMD-20250504000000" # This Commander Task ID
# --- Relationships ---
related_tasks = ["TASK-ARCH-20250504000000"] # Depends on metrics definition
related_docs = [
    ".ruru/docs/metrics_definitions.md", # Primary input
    "docs/architecture.md",
    "docs/requirements.md",
    "reinforcestrategycreator/",
    "train.py",
    "analyze_results.py"
    ] # List of relevant file paths
# --- Context & Details ---
tags = ["metrics", "kpi", "backend", "api", "database", "timeseries", "logging", "calculation", "implementation"]
# --- Time & Effort ---
# estimated_effort = "large" # e.g., "2h", "1d", "small", "medium", "large"
# actual_effort = "..."
# due_date = "YYYY-MM-DD"
+++

# Task: Implement Backend for Performance Metrics

## 🎯 Goal

Implement the backend system modifications required to calculate, store, log, and expose the performance metrics defined in `.ruru/docs/metrics_definitions.md` via secure and efficient API endpoints, enabling dashboard integration and analysis.

## 📖 Description

Based on the metric definitions and the original user request, the backend team needs to:

1.  **Implement Calculation Logic:** Integrate the calculation logic for all defined metrics (PnL, Reward, Sharpe, MDD, Win Rate, etc.) into the system. This might involve modifying `analyze_results.py`, `trading_environment.py`, or creating new dedicated modules.
2.  **Design & Implement Data Storage:** Choose and implement a suitable persistent storage solution. Consider if existing storage (e.g., `training_log.csv`) is sufficient or if a database (SQL or NoSQL) or a time-series database (like InfluxDB, TimescaleDB) is required for the specified granularity and query performance. Define and implement necessary schema changes.
3.  **Implement Logging:** Ensure metric values are logged appropriately during training/simulation runs and potentially during analysis.
4.  **Create API Endpoints:** Design and implement secure, efficient API endpoints for retrieving metric data. The API should support filtering (e.g., by date range, strategy, agent) and aggregation as needed for the dashboard. Consider using a framework like FastAPI or Flask if not already in place.
5.  **Testing:** Implement unit and integration tests for the calculation logic and API endpoints.
6.  **Documentation:** Update relevant documentation (e.g., `docs/architecture.md`, potentially add API documentation).

## ✅ Acceptance Criteria

*   Calculation logic for all metrics in `.ruru/docs/metrics_definitions.md` is implemented correctly.
*   A robust data storage solution is implemented and integrated.
*   Metric data is persistently stored with the required granularity.
*   Metrics are logged effectively.
*   API endpoints are created, functional, secure, and meet the retrieval requirements (filtering, aggregation).
*   Endpoints are documented (e.g., OpenAPI spec if using FastAPI).
*   Code changes are tested.
*   Relevant architecture/system documentation is updated.

## 📋 Checklist

*   [✅] Analyze metric definitions (`.ruru/docs/metrics_definitions.md`).
*   [✅] Design data storage strategy (DB type, schema).
*   [✅] Implement data storage solution (schema changes, setup).
*   [ ] Implement calculation logic for PnL.
*   [ ] Implement calculation logic for Total Reward.
*   [ ] Implement calculation logic for Sharpe Ratio.
*   [ ] Implement calculation logic for Max Drawdown.
*   [ ] Implement calculation logic for Win Rate.
*   [ ] Implement calculation logic for Trade Frequency.
*   [ ] Implement calculation logic for Success Rate.
*   [ ] Implement calculation logic for Steps Per Episode.
*   [ ] Implement calculation logic for Resource Consumption metrics.
*   [ ] Integrate calculations into training/simulation/analysis workflows.
*   [ ] Implement logging for metric data.
*   [ ] Design API endpoints (routes, request/response formats).
*   [ ] Implement API endpoints.
*   [ ] Implement filtering/aggregation capabilities in API.
*   [ ] Implement security measures for API endpoints.
*   [ ] Write unit/integration tests for calculations.
*   [ ] Write tests for API endpoints.
*   [ ] Update/create documentation (architecture, API).
*   [ ] Coordinate with Frontend Lead regarding API specifics.

## 🪵 Log

*   2025-05-04 - Task created by Roo Commander.
*   2025-05-04 - Delegated database schema implementation and setup to Database Lead via task `TASK-DB-LEAD-20250504000430`.
*   2025-05-04 - Delegated metrics calculation and DB integration to Python Developer via task `TASK-PY-DEV-20250504000700`.